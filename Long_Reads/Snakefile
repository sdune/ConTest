# Configfile
configfile: "config.yaml"

# Variables
ACC, IDS, = glob_wildcards(config["path"]+"{accall}.fastq.gz")
GENOMENONSELF, = glob_wildcards(config["taxdb_path"]+config["nonself"]+"/{genomenonself}.gz")
GENOMESELF, = glob_wildcards(config["taxdb_path"]+config["self"]+"/{genomeself}.gz")

# Exclude test-genome from self database 
ind = GENOMESELF.index(config["test_genome"])              
del GENOMESELF[ind]

GENOME = GENOMENONSELF+GENOMESELF
TAX = [config["nonself"]] * len(GENOMENONSELF) + [config["self"]] * len(GENOMESELF)

# Wildcard constraints
wildcard_constraints:
    id="\d",
    tax="\s+",
    taxon="[^_]+"

# Target rule
rule all:
    input:
        expand("LR_{te}/{acc}.reciprocal.fasta", acc=ACC, te=config["TE"])

# Identification of TE in reads 
rule diamond:
    input:
        fasta = "00_fastq/{acc}.fastq.gz",
        TE = lambda wildcards: config["TE"][wildcards.te]
    output:
        "LR_{te}/{acc}.out6"
    log:
        "logs/LR_{te}/{acc}.log"
    threads:
        32
    shell:  
        "diamond blastx --threads {threads} --db {input.TE} --out {output} --outfmt 6 --query {input.fasta} --more-sensitive"

# Get names of reads with TE
rule get_read_ids:
    input:
        "LR_{te}/{acc}.out6"
    output:
        "LR_{te}/{acc}_filtered.txt"
    shell:
        """
        set +oue
        awk -F'\t' '$10<1e-10 {print $1}' {input} > {output} 
        set -oue
        """

# Make fasta file with reads containing TE
rule get_reads:
    input:
        reads="LR_{te}/{acc}_filtered.txt",
        fastq="00_fastq/{acc}.fastq.gz"
    output:
        "LR_{te}/{acc}.dmndhits.fasta"
    shell:
        "seqtk subseq {input.fastq} {input.reads} | seqtk seq -a - > {output} "


# Mask reads
rule RepeatMasker:
    input:
        "LR_{te}/{acc}.dmndhits.fasta"
    output:
        "LR_{te}/{acc}.dmndhits.fasta.out"
    threads:
        32
    params:
        outdir="LR_{te}",
        repbase=config["TEdb"]
    shell:
        """
        mkdir outdir;
        RepeatMasker -pa {threads} -s -no_is -nocut -nolow -lib {params.repbase} -dir {params.outdir} {input} 
        """


# Select reads that were masked as TE 
rule get_reciprocal_reads:
    input: "LR_{te}/{acc}.dmndhit.fasta.out"
    output: "LR_{te}/{acc}.reciprocal.txt"
    params:
        tefasta=lambda wildcards: config["TE"][wildcards.te]
    shell:
        """
        grep -f <(grep '>' {params.tefasta} | cut -f 1 | sed 's/>//g') {input} |
        sort -k5,5 -k1,1g |
        awk '{{print $0,"\t",$5}}' |
        uniq -f 15 |
        awk '{{print $5}}' > {output}
        """

# Make fasta file with reads
rule get_reciprocal_fastas:
    input:
        "LR_{te}/{acc}.reciprocal.txt"
    output:
        "LR_{te}/{acc}.reciprocal.fasta"
    params:
        out="{acc}"
    shell:
        """
        seqtk subseq LR_{te}/{acc}.dmndhits.fasta {input} > {output}
        """

# Blast reads against genome databases
rule blast_vs_taxOne:
    input:
        reads="LR_{te}/{acc}.reciprocal.fasta",
        db="/home/sdunemann/db/genomes/{taxon}/{genome}.gz"
    output:
        "LR_{te}/{taxon}_{genome}_{acc}.out6"
    threads:
        56
    params:
        dbsize=config["dbsize"]
    shell:
        "blastn -db {input.db} -dbsize {params.dbsize} -query {input.reads} -evalue 1e-03 -outfmt 6 -out {output} -num_threads {threads};"


# Get results
rule taxonomy:
    input:
        expand(expand("LR_{{te}}/{taxon}_{genome}_{{acc}}.out6",zip,taxon=TAX,genome=GENOME), te=config["TE"], acc=ACC),
    output:
        hits="taxonomy_besthits.{te}.txt",
        taxresults="taxonomy_taxa.{te}.txt",
        specresults="taxonomy_species.{te}.txt"
    params:
        te="{te}"
    shell:
        """
        set +eou;
        for i in `find LR_{params.te}/*.out6 -not -empty` ; do
            cat $i >>temp.txt;
        done ;
        sort -k16,16 -k12,12gr temp.txt | uniq -f 15 > {output.hits} ;
        cut -f 13 {output.hits} | sort | uniq -c > {output.taxresults};
        cut -f 14 {output.hits} | sort | uniq -c > {output.specresults};
        rm temp.txt;
        set -eou;
        """

rule report:
    params:
       TE=lambda wildcards: config["TE"][wildcards.te]
    input:
        results="taxonomy_results_{params.TE}.txt",
        stats="taxonomy_stats_{params.TE}.txt"
    output: "report.html"
    run:
        from snakemake.utils import report
        with open(input[1]) as stats:
            f=print (stats.read())
        report("""
        Differentiate between endemic and non-endemic sequences based on read pairs workflow
        ====================================================================================
        
        Reads were converted from fastq to fasta and hard-masked if quality under 20. Reads were then blasted against TE        of interest with evalue cutoff of 1e-03. Reads with positive hits were filtered and repeatmasked for TE of inter        est to confirm blast result. Read mates of reads with confirmed TE were checked if they are also TE sequences. I        f not, they were masked for all TEs and then blasted against different taxonomy databases to assess taxon of ori        gin (original or other phylum). 
        {f}
        S_
        """, 
        output[0], R=input[0], S=input[1]
        )
